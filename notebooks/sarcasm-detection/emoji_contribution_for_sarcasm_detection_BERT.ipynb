{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Saracasm Detection by Emojis\n",
        "## By: Rivka Sheiner\n",
        "## Purpose: to know the contribution of emojis for sarcasm detection"
      ],
      "metadata": {
        "id": "XHX0ryrQ6Xsr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the dataset of sarcastic and non sarcastic tweets with emojis and splitting it into train and test sets"
      ],
      "metadata": {
        "id": "4OnnFpy36hmw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzsGkdjhYevs",
        "outputId": "5dd2303a-6862-461a-a37c-020a3ecf65ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1X1jZgrRaVH-h0xX3k8cSzT0kumIVlmwx\n",
            "To: /content/sarc_emojis_1000.csv\n",
            "100% 1.60M/1.60M [00:00<00:00, 42.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1--LLxkODAryG3TgUHrcggfrYoXnr9UFe\n",
            "To: /content/not_sarc_emojis_1000.csv\n",
            "100% 1.68M/1.68M [00:00<00:00, 45.3MB/s]\n"
          ]
        }
      ],
      "source": [
        "! gdown 1X1jZgrRaVH-h0xX3k8cSzT0kumIVlmwx #sarc_emojis_1000.csv\n",
        "! gdown 1--LLxkODAryG3TgUHrcggfrYoXnr9UFe #not_sarc_emojis_1000.csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "xDu-tOKqYiFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the sarcastic and non sarcastic tweets with emojis\n",
        "sarcastic_df = pd.read_csv('sarc_emojis_1000.csv')\n",
        "non_sarcastic_df = pd.read_csv('not_sarc_emojis_1000.csv')\n",
        "\n",
        "# Append emoticon to text in both datasets\n",
        "sarcastic_df['text'] = sarcastic_df['text'] + ' ' + sarcastic_df['label']\n",
        "non_sarcastic_df['text'] = non_sarcastic_df['text'] + ' ' + non_sarcastic_df['label']\n",
        "\n",
        "# Add labels to the data\n",
        "sarcastic_df['class'] = 1  # 1 for sarcastic\n",
        "non_sarcastic_df['class'] = 0  # 0 for non sarcastic\n",
        "\n",
        "# Combine sarcstic and non sarcastic tweets\n",
        "df = pd.concat([sarcastic_df, non_sarcastic_df], ignore_index=True)\n",
        "\n",
        "# Shuffle the data\n",
        "df = df.sample(frac=0.1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['class'], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "XMwTW6r-Yh_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unique emoticons list from the 'label' column\n",
        "all_emoticons_list = df['label'].unique()"
      ],
      "metadata": {
        "id": "zGslvsEGZzyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_emoticons_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bR0aWy48Z4Mn",
        "outputId": "959966f6-76f9-422f-b34e-35fbc7f9d1ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['😐', '👏', '😏', '😊', '😁', '🤔', '😡', '👍', '😳', '😑', '😄', '👌', '😃',\n",
              "       '☺', '😔', '😜', '😂', '😒', '🙄', '😉'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Emojis Results with BERT"
      ],
      "metadata": {
        "id": "LP75B_Hk6rBm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, AdamW\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "\n",
        "texts = df['text'].tolist()\n",
        "labels = df['class'].tolist()\n",
        "\n",
        "# Load pre-trained DistilBERT model and tokenizer\n",
        "model_name = 'distilbert-base-uncased'\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
        "model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=2)  # Assuming binary classification\n",
        "\n",
        "# Tokenize and encode the input texts\n",
        "inputs = tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n",
        "\n",
        "# Create TensorDataset for training\n",
        "dataset = TensorDataset(inputs['input_ids'], inputs['attention_mask'], torch.tensor(labels))\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "\n",
        "# Define data loaders\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "# Define optimizer and training parameters\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "epochs = 4\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        input_ids, attention_mask, label = batch\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=label)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    avg_loss = total_loss / len(train_dataloader)\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Average Training Loss: {avg_loss}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIw547DwYlBk",
        "outputId": "a6b33a3d-7977-4ca8-9bfc-8eeb45c1d642"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.weight', 'pre_classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4, Average Training Loss: 0.6681870031356811\n",
            "Epoch 2/4, Average Training Loss: 0.5674539041519165\n",
            "Epoch 3/4, Average Training Loss: 0.4612859606742859\n",
            "Epoch 4/4, Average Training Loss: 0.3606361949443817\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation on the test set\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_dataloader:\n",
        "        input_ids, attention_mask, label = batch\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        preds = torch.argmax(logits, dim=1).tolist()\n",
        "        all_preds.extend(preds)\n",
        "        all_labels.extend(label.tolist())\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(all_labels, all_preds)\n",
        "precision = precision_score(all_labels, all_preds)\n",
        "recall = recall_score(all_labels, all_preds)\n",
        "f1 = f1_score(all_labels, all_preds)\n",
        "\n",
        "print('BERT results: \\n')\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CatoiHl7a-zL",
        "outputId": "c901d047-e1aa-4519-8ee6-2c1f66352574"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT results: \n",
            "\n",
            "Accuracy: 0.7275\n",
            "Precision: 0.8162544169611308\n",
            "Recall: 0.5818639798488665\n",
            "F1 Score: 0.6794117647058824\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Analysis for misclassifications with emoticon details and FP/FN examples\n",
        "test_df = pd.DataFrame({'text': X_test, 'true_label': all_labels, 'predicted_label': all_preds})\n",
        "\n",
        "for emoticon in all_emoticons_list:\n",
        "    df_filtered = test_df[test_df['text'].str.contains(emoticon, regex=False)]\n",
        "\n",
        "    if len(df_filtered) > 0:\n",
        "        emoticon_accuracy = accuracy_score(df_filtered['true_label'], df_filtered['predicted_label'])\n",
        "\n",
        "        # False Positives: Predicted as 1 but true label is 0\n",
        "        fp_examples = df_filtered[(df_filtered['predicted_label'] == 1) & (df_filtered['true_label'] == 0)]['text'].head(3)\n",
        "\n",
        "        # False Negatives: Predicted as 0 but true label is 1\n",
        "        fn_examples = df_filtered[(df_filtered['predicted_label'] == 0) & (df_filtered['true_label'] == 1)]['text'].head(3)\n",
        "\n",
        "        print(f\"\\nEmoticon: {emoticon}, Accuracy: {emoticon_accuracy:.4f}, Count: {len(df_filtered)}\")\n",
        "\n",
        "        # Display FP and FN examples\n",
        "        if not fp_examples.empty:\n",
        "            print(\"\\nFalse Positives:\")\n",
        "            for example in fp_examples:\n",
        "                print(f\"- {example}\")\n",
        "\n",
        "        if not fn_examples.empty:\n",
        "            print(\"\\nFalse Negatives:\")\n",
        "            for example in fn_examples:\n",
        "                print(f\"- {example}\")\n",
        "    else:\n",
        "        print(f\"\\nEmoticon: {emoticon}, No samples in test set.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lw7OqDcDx_as",
        "outputId": "d10831ed-2c8d-43d2-bd16-3b8755953434"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Emoticon: 😐, Accuracy: 0.7317, Count: 41\n",
            "\n",
            "False Positives:\n",
            "- glad my sisters car works 100% and we didn't have to stay out in the snow for 20 minutes fixing it..  😐\n",
            "- exactly: politics is not religion; and if in religion all are sinners- is it not then more likely that politics all are 'criminals'???  😐\n",
            "\n",
            "False Negatives:\n",
            "- i just had a dream that made me so nervous n anxious that it woke me up  i’m so exhausted, i can’t stand being awake one more second 😐\n",
            "- disappointment is not finding your favourite actor in the sequel of a movie. 😐\n",
            "- le me in stats/maths exam:sir steps ky marks milein gay?sir:beta exam hai dance plus nhi 😐\n",
            "\n",
            "Emoticon: 👏, Accuracy: 0.7045, Count: 44\n",
            "\n",
            "False Positives:\n",
            "- ooowee.... very good photo 👏\n",
            "- congrats ba คนใหม่ด้วยนะคะba burberry brightbright vachirawit 👏\n",
            "- thank you for your behaviour  👏\n",
            "\n",
            "False Negatives:\n",
            "- great job  i love the way some stories from childhood stay with us and keep niggling as we move through life. 👏\n",
            "- that'll be amazing  👏\n",
            "- not only was my bus mega late but it is now also going in the wrong direction 👏\n",
            "\n",
            "Emoticon: 😏, Accuracy: 0.7442, Count: 43\n",
            "\n",
            "False Positives:\n",
            "- please respect your boyfriends because we're referring them to good girls and they chose you with foreheads that look like hospital buckets.. 😏\n",
            "- well it's about damn time...  😏\n",
            "- to filo teumes in naia, show them how it's properly done.  😏\n",
            "\n",
            "False Negatives:\n",
            "- yes, because the bbc, cbc, rtê, ard, al jazeera, etc are completely incapable of broadcasting news.  😏\n",
            "- yeah he did! apparently what he says and does is a real hot topic and important in regards to the direction of our country right now, everyone around the water cooler is talkin about it.  😏\n",
            "- well that's promising for anyone with allergies, arthritis, or connective tissue disease  😏\n",
            "\n",
            "Emoticon: 😊, Accuracy: 0.7500, Count: 40\n",
            "\n",
            "False Positives:\n",
            "- this is going to be a great day!  😊\n",
            "\n",
            "False Negatives:\n",
            "- oh so we have opposite times, and no you can deal with that on your own 😊\n",
            "- no one knows how generous this kid is.... he got me a bike seat 😊\n",
            "- i love kamote especially the purple ones.  😊\n",
            "\n",
            "Emoticon: 😁, Accuracy: 0.7179, Count: 39\n",
            "\n",
            "False Positives:\n",
            "- i’m drinking it rn  😁\n",
            "- \"omgsh yea jess! carrie underwood remembered u from 10 years ago!\"  😁\n",
            "- make sure to follow all the requirements for the tip  😁\n",
            "\n",
            "False Negatives:\n",
            "- it’s not my business o. as i dey laugh, follow me dey laugh. simple  😁\n",
            "- that's really going out on a limb there, rr  😁\n",
            "- awesome update. now i can't open the app at all.  😁\n",
            "\n",
            "Emoticon: 🤔, Accuracy: 0.8750, Count: 32\n",
            "\n",
            "False Negatives:\n",
            "- a lie you are caught doing or did=mistake/what definition were you using?/ 🤔\n",
            "- i wonder if trump will ever be on jimmy kimmel's  🤔\n",
            "- ashame you cant trust \"good conservative church goin folk\"  🤔\n",
            "\n",
            "Emoticon: 😡, Accuracy: 0.8571, Count: 35\n",
            "\n",
            "False Positives:\n",
            "- wow, is being really nice to me today.  😡\n",
            "\n",
            "False Negatives:\n",
            "- are divinely chosen and know better than their constituents. somebody has to protect us from ourselves.  😡\n",
            "- obsessed with hip rolls grrr  😡\n",
            "- its all bl‐--,,,dy political the union could not except brexit and couldnt have the sticky fingers in the eu s pie  😡\n",
            "\n",
            "Emoticon: 👍, Accuracy: 0.7879, Count: 33\n",
            "\n",
            "False Positives:\n",
            "- oh no! we just ran out of lifetime supplies... but we will happily give out free a thumbs up  👍\n",
            "\n",
            "False Negatives:\n",
            "- give your bungalow and go to their huts. don't forget to take arfa and varadarajan. o.k. be quick. . 👍\n",
            "- i love a little with my sunday morning coffee..thanks  👍\n",
            "- thanks for cutting off the game to do pregame!  👍\n",
            "\n",
            "Emoticon: 😳, Accuracy: 0.7250, Count: 40\n",
            "\n",
            "False Positives:\n",
            "- i was in france a month ago too  😳\n",
            "\n",
            "False Negatives:\n",
            "- how are y’all wearing wings in this heat  😳\n",
            "- „last time you tried to sleep with me“  😳\n",
            "- it worked with friends  i'm weird and awkward...girls love it... 😳\n",
            "\n",
            "Emoticon: 😑, Accuracy: 0.6053, Count: 38\n",
            "\n",
            "False Positives:\n",
            "- on route to my favourite place in edinburgh!  😑\n",
            "- thanks for locking my old account now i get to create a new one and start all over again  😑\n",
            "- the idea is better than watching it, it was hilarious at the time no denying but if i watched it back now it’d be a lot of  😑\n",
            "\n",
            "False Negatives:\n",
            "- i love getting up at 5.30am on a sunday  😑\n",
            "- i don't think roberto's put enough fucking onions on my carne asada fries  😑\n",
            "- the only way i was able to make patients wear masks properly for a few weeks was by writing a note saying that i was seeing covid patients daily. they were like “really???”no dude… 1,5 year into a pandemic and as a front line gp i haven’t seen any covid at all 😑\n",
            "\n",
            "Emoticon: 😄, Accuracy: 0.6585, Count: 41\n",
            "\n",
            "False Positives:\n",
            "- hehe 0 out of that 15%  loving this sem.. 😄\n",
            "- i wish you the utmost good luck, in achieving your grandiose goal, dawn! (i speak too)  😄\n",
            "\n",
            "False Negatives:\n",
            "- up drinking like i don’t work at 6am  😄\n",
            "- let's just be rude, it's all good!  😄\n",
            "- hull set i've had 2 of then here this morning haha  😄\n",
            "\n",
            "Emoticon: 👌, Accuracy: 0.8056, Count: 36\n",
            "\n",
            "False Positives:\n",
            "- wow refs, i'm glad you decided not to throw any flags today  👌\n",
            "- being criticized daily really boosts your self-esteem 👌\n",
            "\n",
            "False Negatives:\n",
            "- real glad i got a lot planned for today 👌\n",
            "- forgot my calculator for my math test  today is gonna be a good day 👌\n",
            "- ya, it’s a very good team. however, you can follow the updates of the players especially for the 4.5 &amp; 5.0 m players who could be compared to the one you picked and maybe better  👌\n",
            "\n",
            "Emoticon: 😃, Accuracy: 0.7568, Count: 37\n",
            "\n",
            "False Negatives:\n",
            "- early morning wotowoto.don't worry my dear, i'll tell esther to make compensation cake for you  😃\n",
            "- can't wait to work today  😃\n",
            "- looks like a roll of lifesavers  😃\n",
            "\n",
            "Emoticon: ☺, Accuracy: 0.7647, Count: 34\n",
            "\n",
            "False Negatives:\n",
            "- in english we call it ,only smart peeps get it \": den u nid carrots 2c wah i wrote!\" ☺\n",
            "- cant wait for jungkook to post a short cover of your river in my heart on ig  ☺\n",
            "- baby where ua shirt ☺\n",
            "\n",
            "Emoticon: 😔, Accuracy: 0.6571, Count: 35\n",
            "\n",
            "False Positives:\n",
            "- no poldoski for the north london derby ..just great  😔\n",
            "- there never was peace  😔\n",
            "- wow thanks, ur so nice  😔\n",
            "\n",
            "False Negatives:\n",
            "- i like how i never see you and the one time i do, you ignore me.  😔\n",
            "- heading back to dads, school tommorow yay .. 😔\n",
            "- actual good person count down to a solid 1.  😔\n",
            "\n",
            "Emoticon: 😜, Accuracy: 0.8043, Count: 46\n",
            "\n",
            "False Positives:\n",
            "- president of chor union  😜\n",
            "- oh... i didn't tell you... then it must be none of your business.  😜\n",
            "\n",
            "False Negatives:\n",
            "- gotta love those people following only to unfollow two days later, why would you?  don't bother answering i'm being 😜\n",
            "- finding out you're allergic to something is always wonderful  😜\n",
            "- but ma'am, isn't that what you do?  is easy to do and its think people...sigh 😜\n",
            "\n",
            "Emoticon: 😂, Accuracy: 0.6383, Count: 47\n",
            "\n",
            "False Positives:\n",
            "- i learn from the mistakes of people who took my advice.  😂\n",
            "- hey no, is very concerned about kids going to college now. i mean, she probably only means white kids if we read between the lines, but she is very concerned about them overall.  😂\n",
            "- i keep changing the profile picture.  😂\n",
            "\n",
            "False Negatives:\n",
            "- she has to take accountability because she decided to have the child duh  why didn't she abort the child than if she knew she would have problems taking care of him/her ??? 😂\n",
            "- lmao!! they say,'be you', until their own benefit is fulfilled,trust me they'll never care after that..apart from judging you 😂\n",
            "- the game is a scam trap.the rates are shit with caps.you need atleast 300 red gadgets (their coin) to be able to withdraw. now that's just the qualification amount.on that 300 red gadget permission you can only withdraw 100  😂\n",
            "\n",
            "Emoticon: 😒, Accuracy: 0.6739, Count: 46\n",
            "\n",
            "False Positives:\n",
            "- how is that bad? oh wait, let’s preserve the racist plantation owner history instead!  😒\n",
            "- no, you can’t say this  😒\n",
            "- whoever that girl on the video, fck u  😒\n",
            "\n",
            "False Negatives:\n",
            "- no ma'am  send funds 😒\n",
            "- if that doesn't result in a suspension, i might just have to whine about it, because...you know...pittsburgh whines  😒\n",
            "- i hate when i can’t sleep  😒\n",
            "\n",
            "Emoticon: 🙄, Accuracy: 0.6923, Count: 39\n",
            "\n",
            "False Positives:\n",
            "- a screenshot of a part she was playing as an actress? or in real life? oh you can tell which it was, you were there!!  🙄\n",
            "- you're saying indianapolis has &lt;checks notes&gt; hot, young, virgin, adult women who want you impregnate them, and are willing to obey you?!they need to add these questions to the census where i live. i haven't found a single one near me that meets those requirements.  🙄\n",
            "- you can compare bella and shellz ship with any past ship but not emmarose if emma had chased rose like this, rose for born 10 children in biggies house  🙄\n",
            "\n",
            "False Negatives:\n",
            "- can’t go back to sleep so i guess i’ll go to the gym  🙄\n",
            "- duh. it's not airborne!  🙄\n",
            "- now we see why you have seven followers  🙄\n",
            "\n",
            "Emoticon: 😉, Accuracy: 0.6852, Count: 54\n",
            "\n",
            "False Positives:\n",
            "- oh and just a tiny bit of in that tweet. just a wee bit, mind you.  😉\n",
            "- just make sure it's a lot like christopher reeve  😉\n",
            "- when i was a child (in the 70s), we were taught meticulous grammar and syntax and, as it was my best subject, i picked it up well and it stayed with me forever. i really think it's neglected now, in favor of the more important things like gender theory and crt.  😉\n",
            "\n",
            "False Negatives:\n",
            "- i think you missed the hashtag  😉\n",
            "- however benny split like that his moves have lessened and weakened to light and chip damage. while gerald has more attack and slowly loses health won't ko like this.their ultimate has him and a group of bennys \"gang up\" on some one by one attack combo. ultimate.  😉\n",
            "- \"watching the best (episode 1: the phantom menace) movie  right now on tnt.\" 😉\n"
          ]
        }
      ]
    }
  ]
}