{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPb+u0V+RbbCWgqtmG2wN9W"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"bfccbac0a3b64414880be6121eeb39ce":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_85f4de22706548d78022bcc3dae332b9","IPY_MODEL_1febf96b1a124563a558815649641f22","IPY_MODEL_aed81c207c59419994699556d0dbbbdc"],"layout":"IPY_MODEL_5ed006b60606454bb4482bb93ef49fd6"}},"85f4de22706548d78022bcc3dae332b9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3bb6386f8af3464eb38670baae06e2bb","placeholder":"​","style":"IPY_MODEL_d027cc7d094b4724bef3d486b91aa97a","value":"100%"}},"1febf96b1a124563a558815649641f22":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c7fc08fd25b34b5f86652f1e53677c98","max":9,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e4ea012b2f6949d7a731a07b9adbcd61","value":9}},"aed81c207c59419994699556d0dbbbdc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f963cdbed86d438095a59ad6c8eb8346","placeholder":"​","style":"IPY_MODEL_e9c7e614dcd144dd9cf6ac886ae18498","value":" 9/9 [00:01&lt;00:00,  4.48ba/s]"}},"5ed006b60606454bb4482bb93ef49fd6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3bb6386f8af3464eb38670baae06e2bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d027cc7d094b4724bef3d486b91aa97a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c7fc08fd25b34b5f86652f1e53677c98":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4ea012b2f6949d7a731a07b9adbcd61":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f963cdbed86d438095a59ad6c8eb8346":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9c7e614dcd144dd9cf6ac886ae18498":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7ff98a0cc0d24997b36a2955bf846598":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0f04aab43d7648c88c019ca3c195297c","IPY_MODEL_60ec12a74f8c413481078fcd017b6c9b","IPY_MODEL_352f9455f3554c7cbf5ba3223eddb2ee"],"layout":"IPY_MODEL_31b59001c14f4bdcaebd0a7a58c6e77e"}},"0f04aab43d7648c88c019ca3c195297c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c013a1836c3c4bb6b767e955cdea43f6","placeholder":"​","style":"IPY_MODEL_b92312a031474382972e9fe8d3a47ab7","value":"100%"}},"60ec12a74f8c413481078fcd017b6c9b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc9018311a434871b36cbd9a94b40696","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5fe8f09af110499195de843989eff205","value":3}},"352f9455f3554c7cbf5ba3223eddb2ee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c2a73dbe8a084e8cbfde3e5b0b20aef5","placeholder":"​","style":"IPY_MODEL_9955027e41344719b5def94f1615ca3a","value":" 3/3 [00:00&lt;00:00,  4.79ba/s]"}},"31b59001c14f4bdcaebd0a7a58c6e77e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c013a1836c3c4bb6b767e955cdea43f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b92312a031474382972e9fe8d3a47ab7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fc9018311a434871b36cbd9a94b40696":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5fe8f09af110499195de843989eff205":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c2a73dbe8a084e8cbfde3e5b0b20aef5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9955027e41344719b5def94f1615ca3a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["In this notebook I fine-tuned a bert-based model with the reddit dataset."],"metadata":{"id":"NDgkThZ66Skv"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6NgUo9p2bgHS","executionInfo":{"status":"ok","timestamp":1657722061904,"user_tz":-180,"elapsed":7354,"user":{"displayName":"שוהם יחזקאלי","userId":"00395358315475879624"}},"outputId":"2a116d40-bdf0-4b5c-c6c3-a34c1b7f293b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1U0pQDPYFG1m4ajKU_knjZCQmDMh9jQBp\n","To: /content/train-balanced-sarcasm.csv\n","100% 253M/253M [00:00<00:00, 304MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1J_oVuyf-SlzO1oTRhkB2ci9GbNbZ8ZRp\n","To: /content/sentiment140.csv\n","100% 240M/240M [00:00<00:00, 312MB/s]\n"]}],"source":["! gdown 1U0pQDPYFG1m4ajKU_knjZCQmDMh9jQBp\n","! gdown 1J_oVuyf-SlzO1oTRhkB2ci9GbNbZ8ZRp"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","reddit_data = pd.read_csv('train-balanced-sarcasm.csv')\n","reddit_data['comment'] = reddit_data['comment'].dropna()\n","reddit_data['label'] = reddit_data['label'].dropna()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uZ_Yp9NYblH8","executionInfo":{"status":"ok","timestamp":1657722078133,"user_tz":-180,"elapsed":16235,"user":{"displayName":"שוהם יחזקאלי","userId":"00395358315475879624"}},"outputId":"2859da80-c3b1-4ba9-eff5-155bc0e6b982"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n","  exec(code_obj, self.user_global_ns, self.user_ns)\n"]}]},{"cell_type":"code","source":["!pip install transformers\n","!pip install datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yhEq9VVbb6KN","executionInfo":{"status":"ok","timestamp":1657722084906,"user_tz":-180,"elapsed":6789,"user":{"displayName":"שוהם יחזקאלי","userId":"00395358315475879624"}},"outputId":"74ff4018-e819-446a-ef8e-7104184ecbc8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.20.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.3.2)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.12.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.5.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n","Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.8.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"]}]},{"cell_type":"code","source":["sarcastic_words = [\"obviously\", \"clearly\", \"totally\", \"duh\", \"everyone knows\", \"right because\", \"yeah obviously\", \"yes because\", \"yeah because\",\"shitlord\",\n","                    \" definitely \", \"of course\", \"surely\", \"how dare\", \"duh\", \" gee \", \"for sure\", \"amirite\", \"good thing that\",\"how i love\", \"what a surprise\"]"],"metadata":{"id":"QsaxtQNMr1Lg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import re\n","\n","def clean_com(com):\n","  com = com.lower().replace(',', '')\n","  com = re.sub(r'http\\S+', '', com)\n","  com = re.sub(\"@[A-Za-z0-9_]+\",\"\", com)\n","  com = re.sub(\"#[A-Za-z0-9_]+\",\"\", com)\n","  return re.sub(r'[^A-Za-z\\s]', '', com)"],"metadata":{"id":"UHjMs3bslqRM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from datasets.dataset_dict import DatasetDict\n","from sklearn.model_selection import train_test_split\n","from datasets import Dataset\n","\n","X = []\n","Y = []\n","\n","for com,y in zip(reddit_data['comment'].tolist(), reddit_data['label'].tolist()):\n","  if type(com) is str and str(y).isdigit():\n","    x = clean_com(com)\n","    if 20 < len(x) < 150 and any(com in x for com in sarcastic_words):      \n","      X.append(x)\n","      Y.append(int(y))\n","\n","X1 = []\n","Y1 = []\n","c0 = 0\n","c1 = 0\n","\n","for x,y in zip(X,Y):\n","  if y == 0: \n","    if c0 >= 5500: continue\n","    c0 += 1\n","  else: \n","    if c1 >= 5500: continue\n","    c1 += 1\n","  X1.append(x)\n","  Y1.append(y)"],"metadata":{"id":"mbsU0S_yb8J_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["a = [x for x,y in zip(X1,Y1) if y == 1]\n","b = [x for x,y in zip(X1,Y1) if y == 0]\n","print(len(a),len(b))\n","b[20:50]\n","#b[40:50]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3JAqrtYP4mhE","executionInfo":{"status":"ok","timestamp":1657724498226,"user_tz":-180,"elapsed":475,"user":{"displayName":"שוהם יחזקאלי","userId":"00395358315475879624"}},"outputId":"4b56fc7c-a71f-4494-8d60-857c6e8fe522"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["5500 5500\n"]},{"output_type":"execute_result","data":{"text/plain":["['yup winning by millions of votes is totally cheating',\n"," 'all  our specs arent the best dps in every situation so we must be nerfed to shit and bad obviously',\n"," 'that guy clearly must be an industrial terrorist',\n"," 'shed be retired from westworld for sure thank god because no one would want anything to do with her',\n"," 'yes of course and i am always open to hear about new opportunities',\n"," 'neither does ap really definitely not worth our best lineman',\n"," 'yea i agree clearly bias has been committed',\n"," 'not surprised that you are literally insulting me clearly im literally winning this argument',\n"," 'i suppose you could make this up if you really wanted to but why would you want to make it up when its obviously happening all over the place',\n"," 'right thats totally what theyre doing',\n"," 'then hes clearly just using that girl for sexual purposes',\n"," 'we could surely win as many games as the browns this year',\n"," 'did you know that  of statistics quoted on the internet are totally made up',\n"," 'ur and erbil are totally different places',\n"," 'no youre definitely being mocked',\n"," 'i cant speak for you of course but i would eat a bullet if i had to do that',\n"," 'he obviously talked about the next major i hope',\n"," 'because definitely all of the protesters there condone the bad actions of a few',\n"," 'i mean youre totally right but if michigan squeaks in and wins you better believe im gonna be celebrating like any other michigan fan',\n"," 'i dont disagree with you but theres still a threshold to which it crosses over into entitlement and hes definitely found it',\n"," 'how can someone come to believe something like this when its so clearly baseless',\n"," 'harry potter the chosen one is quite obviously neville',\n"," 'for sure but the one variable i would say is msu',\n"," 'of course it was a team effort but it is no coincidence that they are doing so much worse this season when he was the only big name to leave',\n"," 'you should totally record the intro so that we can see what youre talking about ',\n"," 'they listen to kanye west so of course they do dd',\n"," 'this just totally made prime worth it',\n"," 'totally relaxed robin this morning pecking away on some scraps',\n"," 'ohhhh i wasnt taking super into account of course p',\n"," 'you can actually but you obviously lose anything that was reliant on your classic mods']"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["x_train,x_test,y_train,y_test = train_test_split(X1,Y1,random_state=42)\n","\n","d = {'train':Dataset.from_dict({'label':y_train,'text':x_train}),\n","     'test':Dataset.from_dict({'label':y_test,'text':x_test})}\n","\n","dataset = DatasetDict(d)"],"metadata":{"id":"yS34UONr4i_O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoTokenizer\n","from transformers import AutoModelForSequenceClassification\n","from transformers import TrainingArguments, Trainer\n","from datasets import load_metric\n","tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n","\n","def tokenize_function(examples):\n","    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n","\n","\n","tokenized_datasets = dataset.map(tokenize_function, batched=True)\n","\n","model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2)\n","training_args = TrainingArguments(output_dir=\"test_trainer\",evaluation_strategy=\"epoch\", num_train_epochs=3)\n","metric = load_metric(\"accuracy\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["bfccbac0a3b64414880be6121eeb39ce","85f4de22706548d78022bcc3dae332b9","1febf96b1a124563a558815649641f22","aed81c207c59419994699556d0dbbbdc","5ed006b60606454bb4482bb93ef49fd6","3bb6386f8af3464eb38670baae06e2bb","d027cc7d094b4724bef3d486b91aa97a","c7fc08fd25b34b5f86652f1e53677c98","e4ea012b2f6949d7a731a07b9adbcd61","f963cdbed86d438095a59ad6c8eb8346","e9c7e614dcd144dd9cf6ac886ae18498","7ff98a0cc0d24997b36a2955bf846598","0f04aab43d7648c88c019ca3c195297c","60ec12a74f8c413481078fcd017b6c9b","352f9455f3554c7cbf5ba3223eddb2ee","31b59001c14f4bdcaebd0a7a58c6e77e","c013a1836c3c4bb6b767e955cdea43f6","b92312a031474382972e9fe8d3a47ab7","fc9018311a434871b36cbd9a94b40696","5fe8f09af110499195de843989eff205","c2a73dbe8a084e8cbfde3e5b0b20aef5","9955027e41344719b5def94f1615ca3a"]},"id":"VtzOn0SYciyT","executionInfo":{"status":"ok","timestamp":1657724520224,"user_tz":-180,"elapsed":15200,"user":{"displayName":"שוהם יחזקאלי","userId":"00395358315475879624"}},"outputId":"7a7717db-d396-4f45-cf18-d5f820f24c02"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n","Model config BertConfig {\n","  \"_name_or_path\": \"bert-base-cased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.20.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading file https://huggingface.co/bert-base-cased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/6508e60ab3c1200bffa26c95f4b58ac6b6d95fba4db1f195f632fa3cd7bc64cc.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791\n","loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/226a307193a9f4344264cdc76a12988448a25345ba172f2c7421f3b6810fddad.3dab63143af66769bbb35e3811f75f7e16b2320e12b7935e216bd6159ce6d9a6\n","loading file https://huggingface.co/bert-base-cased/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/bert-base-cased/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/ec84e86ee39bfe112543192cf981deebf7e6cbe8c91b8f7f8f63c9be44366158.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n","loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n","Model config BertConfig {\n","  \"_name_or_path\": \"bert-base-cased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.20.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/9 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bfccbac0a3b64414880be6121eeb39ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/3 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ff98a0cc0d24997b36a2955bf846598"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n","Model config BertConfig {\n","  \"_name_or_path\": \"bert-base-cased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.20.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file https://huggingface.co/bert-base-cased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/092cc582560fc3833e556b3f833695c26343cb54b7e88cd02d40821462a74999.1f48cab6c959fc6c360d22bea39d06959e90f5b002e77e836d2da45464875cda\n","Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]}]},{"cell_type":"code","source":["def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    predictions = np.argmax(logits, axis=-1)\n","    return metric.compute(predictions=predictions, references=labels)"],"metadata":{"id":"ReG6XQQicmq9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"test\"],\n","    compute_metrics=compute_metrics,\n",")"],"metadata":{"id":"2sirqX5scofg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"UhmuUmPNco_R","outputId":"418c4e25-f85f-4727-a39b-b596280ccf04","executionInfo":{"status":"ok","timestamp":1657727334084,"user_tz":-180,"elapsed":2804291,"user":{"displayName":"שוהם יחזקאלי","userId":"00395358315475879624"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 8250\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3096\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='3096' max='3096' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3096/3096 46:43, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.571000</td>\n","      <td>0.573070</td>\n","      <td>0.713455</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.440400</td>\n","      <td>0.671448</td>\n","      <td>0.721091</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.251800</td>\n","      <td>1.192007</td>\n","      <td>0.703273</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to test_trainer/checkpoint-500\n","Configuration saved in test_trainer/checkpoint-500/config.json\n","Model weights saved in test_trainer/checkpoint-500/pytorch_model.bin\n","Saving model checkpoint to test_trainer/checkpoint-1000\n","Configuration saved in test_trainer/checkpoint-1000/config.json\n","Model weights saved in test_trainer/checkpoint-1000/pytorch_model.bin\n","The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 2750\n","  Batch size = 8\n","Saving model checkpoint to test_trainer/checkpoint-1500\n","Configuration saved in test_trainer/checkpoint-1500/config.json\n","Model weights saved in test_trainer/checkpoint-1500/pytorch_model.bin\n","Saving model checkpoint to test_trainer/checkpoint-2000\n","Configuration saved in test_trainer/checkpoint-2000/config.json\n","Model weights saved in test_trainer/checkpoint-2000/pytorch_model.bin\n","The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 2750\n","  Batch size = 8\n","Saving model checkpoint to test_trainer/checkpoint-2500\n","Configuration saved in test_trainer/checkpoint-2500/config.json\n","Model weights saved in test_trainer/checkpoint-2500/pytorch_model.bin\n","Saving model checkpoint to test_trainer/checkpoint-3000\n","Configuration saved in test_trainer/checkpoint-3000/config.json\n","Model weights saved in test_trainer/checkpoint-3000/pytorch_model.bin\n","The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 2750\n","  Batch size = 8\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=3096, training_loss=0.433717317359392, metrics={'train_runtime': 2803.8117, 'train_samples_per_second': 8.827, 'train_steps_per_second': 1.104, 'total_flos': 6511998620160000.0, 'train_loss': 0.433717317359392, 'epoch': 3.0})"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["#trainer.model.save_pretrained(\"reddit_sarcwords_model\")"],"metadata":{"id":"4EbwiQCHcsNr"},"execution_count":null,"outputs":[]}]}