{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMnmDsw6DhlW2xx82NUGA82"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["This is an example of fine-tuning a bert model. Our sarcastic datasets are not used here."],"metadata":{"id":"mlbhHHHG5KN0"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"r8U6k1lfn_pi"},"outputs":[],"source":["pip install transformers"]},{"cell_type":"code","source":["pip install datasets"],"metadata":{"id":"QVA_r8w6_Vo3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from datasets import load_dataset\n","from transformers import AutoTokenizer, DataCollatorWithPadding\n","import numpy as np\n","\n","raw_datasets = load_dataset(\"glue\", \"mrpc\")\n","checkpoint = \"bert-base-uncased\"\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n","\n","\n","def tokenize_function(example):\n","    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)\n","\n","\n","tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n","\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"tf\")\n","\n","tf_train_dataset = tokenized_datasets[\"train\"].to_tf_dataset(\n","    columns=[\"attention_mask\", \"input_ids\", \"token_type_ids\"],\n","    label_cols=[\"labels\"],\n","    shuffle=True,\n","    collate_fn=data_collator,\n","    batch_size=8,\n",")\n","\n","tf_validation_dataset = tokenized_datasets[\"validation\"].to_tf_dataset(\n","    columns=[\"attention_mask\", \"input_ids\", \"token_type_ids\"],\n","    label_cols=[\"labels\"],\n","    shuffle=False,\n","    collate_fn=data_collator,\n","    batch_size=8,\n",")"],"metadata":{"id":"wPcfk5FkUgwy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import TFAutoModelForSequenceClassification\n","from tensorflow.keras.losses import SparseCategoricalCrossentropy\n","from tensorflow.keras.optimizers.schedules import PolynomialDecay\n","from tensorflow.keras.optimizers import Adam\n","import tensorflow as tf\n","\n","batch_size = 8\n","num_epochs = 3\n","# The number of training steps is the number of samples in the dataset, divided by the batch size then multiplied\n","# by the total number of epochs\n","num_train_steps = len(tf_train_dataset) * num_epochs\n","lr_scheduler = PolynomialDecay(initial_learning_rate=5e-5, end_learning_rate=0.0, decay_steps=num_train_steps)\n","opt = Adam(learning_rate=lr_scheduler)\n","\n","\n","model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n","loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","model.compile(optimizer=opt, loss=loss, metrics=[\"accuracy\"])\n","\n","model.fit(tf_train_dataset, validation_data=tf_validation_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v8WyarBlmSWw","executionInfo":{"status":"ok","timestamp":1643829872747,"user_tz":-120,"elapsed":169066,"user":{"displayName":"שוהם יחזקאלי","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00395358315475879624"}},"outputId":"6ff694ef-ba9b-408a-aef8-2dfbd45da4be"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n","\n","Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["458/458 [==============================] - 166s 323ms/step - loss: 0.6378 - accuracy: 0.6706 - val_loss: 0.6243 - val_accuracy: 0.6838\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f38010c0e50>"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["\n","from datasets import load_metric\n","\n","preds = model.predict(tf_validation_dataset)[\"logits\"]\n","class_preds = np.argmax(preds, axis=1)\n","print(preds.shape, class_preds.shape)\n","\n","for i in range(50):\n","  print(preds[i])\n","\n","#metric = load_metric(\"glue\", \"mrpc\")\n","#metric.compute(predictions=class_preds, references=raw_datasets[\"validation\"][\"label\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iNH5ke5I0oem","executionInfo":{"status":"ok","timestamp":1643834206180,"user_tz":-120,"elapsed":10788,"user":{"displayName":"שוהם יחזקאלי","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00395358315475879624"}},"outputId":"00cf1f71-b5c5-4def-e30f-686394ea9fe2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(408, 2) (408,)\n","[-0.20577943  0.5039454 ]\n","[-0.20558232  0.50362176]\n","[-0.20539574  0.5037148 ]\n","[-0.20537688  0.50398105]\n","[-0.20531353  0.50380045]\n","[-0.20580117  0.5039538 ]\n","[-0.20533745  0.5039904 ]\n","[-0.20557937  0.5036268 ]\n","[-0.20527922  0.50353825]\n","[-0.20540503  0.5036581 ]\n","[-0.20560683  0.50390506]\n","[-0.20536211  0.50375956]\n","[-0.2052948   0.50373054]\n","[-0.20552957  0.50374174]\n","[-0.20547883  0.50409275]\n","[-0.2058427   0.50335675]\n","[-0.20554043  0.5039207 ]\n","[-0.20533559  0.5037407 ]\n","[-0.2056292  0.5041536]\n","[-0.20531698  0.5037804 ]\n","[-0.20527633  0.5035466 ]\n","[-0.20537162  0.5036404 ]\n","[-0.20535259  0.5041412 ]\n","[-0.20566209  0.5037403 ]\n","[-0.20582181  0.5037507 ]\n","[-0.20542145  0.50328606]\n","[-0.205647   0.5035273]\n","[-0.2057134   0.50385886]\n","[-0.20546806  0.5040977 ]\n","[-0.20511107  0.50390106]\n","[-0.20552187  0.50359166]\n","[-0.20567954  0.50405705]\n","[-0.20574899  0.50381356]\n","[-0.20527397  0.5037373 ]\n","[-0.20539422  0.50401306]\n","[-0.20568775  0.50373113]\n","[-0.20572823  0.50342655]\n","[-0.20539354  0.5036909 ]\n","[-0.20548607  0.50363296]\n","[-0.2056617  0.5036918]\n","[-0.20530511  0.50372165]\n","[-0.20543267  0.5039765 ]\n","[-0.20556955  0.50344706]\n","[-0.2053274  0.5039111]\n","[-0.20542587  0.5037788 ]\n","[-0.20547718  0.5039118 ]\n","[-0.20542184  0.5039094 ]\n","[-0.20552395  0.5037539 ]\n","[-0.20553415  0.5035615 ]\n","[-0.20576605  0.5038896 ]\n"]}]},{"cell_type":"code","source":["for i in tf_validation_dataset:\n","  preds = model.predict(i)[\"logits\"]\n","  class_preds = np.argmax(preds, axis=1)\n","  print(class_preds)\n","  #break"],"metadata":{"id":"sqXHZpbp5d-0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["t = tokenizer(\"how are you going to do it\",\"crying is good\",padding = True, return_tensors=\"tf\")\n","preds = model(t)[\"logits\"]\n","prob = tf.nn.softmax(preds)\n","print(prob)\n","class_preds = np.argmax(prob, axis=1)\n","print(class_preds)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2L03T_goGsWH","executionInfo":{"status":"ok","timestamp":1643834081384,"user_tz":-120,"elapsed":977,"user":{"displayName":"שוהם יחזקאלי","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00395358315475879624"}},"outputId":"d15d0cd2-4f88-4f06-a2a3-8cef66df51aa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor([[0.32989815 0.6701018 ]], shape=(1, 2), dtype=float32)\n","[1]\n"]}]}]}